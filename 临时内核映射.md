无论是哪种映射方法，内核映射的本质都是把页框通过一个“窗口”（一个页表项）映射到内核地址空间。

永久内核映射占了一个页全局目录表项，也就是一整个页表，1024（或者512，如果开启PAE的话）个页表项。

而临时内核映射的窗口很少。可用窗口数由KM_TYPE_NR决定，根据是否有__WITH_KM_FENCE参数，分别是41或20个。


enum fixed_addresses数据结构包含符号FIX_KMAP_BEGINhe FIX_KMAP_END；后者的值是FIX_KMAP_BEGIN + (KM_TYPE_NR * NR_CPUS) - 1.

这样一来，系统中的每个CPU都有KM_TYPE_NR个固定映射的线性地址。

另外，内核将FIX_MAP_BEGIN映射的线性地址对应的页表项的地址存在kmap_pte变量中。

内核调用kmap_atomic()函数建立临时内核映射。

`
void *kmap_atomic(struct page *page)
{
	return kmap_atomic_prot(page, kmap_prot);
}
`

kmap_atomic_prot()函数实现如下：
`
void *kmap_atomic_prot(struct page *page, pgprot_t prot)
{
	unsigned long vaddr;
	int idx, type;

	/* even !CONFIG_PREEMPT needs this, for in_atomic in do_page_fault */
	pagefault_disable();

	if (!PageHighMem(page))
		return page_address(page);

	type = kmap_atomic_idx_push();
	idx = type + KM_TYPE_NR*smp_processor_id();
	vaddr = __fix_to_virt(FIX_KMAP_BEGIN + idx);
	BUG_ON(!pte_none(*(kmap_pte-idx)));
	set_pte(kmap_pte-idx, mk_pte(page, prot));
	arch_flush_lazy_mmu_mode();

	return (void *)vaddr;
}
`
页框如果不属于高端内存，那么返回页框的线性地址。

否则，建立该固定映射的线性地址对应的页表项。

最后刷新适当的TLB项并返回线性地址。

撤销临时内核映射：kunmap_atomic()

`
#define kunmap_atomic(addr)                                     \
do {                                                            \
	BUILD_BUG_ON(__same_type((addr), struct page *));       \
	__kunmap_atomic(addr);                                  \
} while (0)
`

`
void __kunmap_atomic(void *kvaddr)
{
	unsigned long vaddr = (unsigned long) kvaddr & PAGE_MASK;

	if (vaddr >= __fix_to_virt(FIX_KMAP_END) &&
	    vaddr <= __fix_to_virt(FIX_KMAP_BEGIN)) {
		int idx, type;

		type = kmap_atomic_idx();
		idx = type + KM_TYPE_NR * smp_processor_id();

#ifdef CONFIG_DEBUG_HIGHMEM
		WARN_ON_ONCE(vaddr != __fix_to_virt(FIX_KMAP_BEGIN + idx));
#endif
		/*
		 * Force other mappings to Oops if they'll try to access this
		 * pte without first remap it.  Keeping stale mappings around
		 * is a bad idea also, in case the page changes cacheability
		 * attributes or becomes a protected page in a hypervisor.
		 */
		kpte_clear_flush(kmap_pte-idx, vaddr);
		kmap_atomic_idx_pop();
		arch_flush_lazy_mmu_mode();
	}
#ifdef CONFIG_DEBUG_HIGHMEM
	else {
		BUG_ON(vaddr < PAGE_OFFSET);
		BUG_ON(vaddr >= (unsigned long)high_memory);
	}
#endif

	pagefault_enable();
}
`
